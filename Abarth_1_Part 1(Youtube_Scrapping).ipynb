{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import xlsxwriter\n",
    "from datetime import datetime\n",
    "\n",
    "api_key = '' #Please insert your key\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due to the daily data extraction limitations of the YouTube API, multiple extraction runs are required. Subsequent data pulls will be merged with previously accumulated data, up to the cut-off time of the prior runs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerunning the code because of API limitations and also further developments on Abarth. Change the keywords according to the needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the specific video IDs from the videos appearing from the searches using the keywords below\n",
    "\n",
    "keywords = ['Abarth EV', 'Abarth Combustion', 'Fiat combustion engine', 'Fiat 500e', 'Tesla EV', \n",
    "'Mini Cooper combustion cars', 'Mini Cooper EV', 'Peugeot Combustion','Peugeot EV', \n",
    "'Volkswagen combustion engine', 'Volkswagen EV'] \n",
    "video_ids = []\n",
    "\n",
    "# This date changes to when the previous run date was cut off. To scrap the latest videos in the next run\n",
    "after_date = '2023-06-02T00:00:00Z'\n",
    "\n",
    "for keyword in keywords:\n",
    "    search_response = youtube.search().list(\n",
    "        q=keyword,\n",
    "        part='id,snippet',\n",
    "        maxResults=25,\n",
    "        type='video',\n",
    "        publishedAfter=after_date\n",
    "    ).execute()\n",
    "    \n",
    "    # Extract video IDs\n",
    "    for item in search_response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        video_ids.append(video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of video_ids\n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty variables for data collection\n",
    "df1_data = []\n",
    "df2_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF1 is the general information about the videos to extract the comments from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section for df1\n",
    "\n",
    "#Filling it into the \"df1_data\"\n",
    "for i in range(0, len(video_ids), 100):\n",
    "    ids_chunk = video_ids[i:i+10]\n",
    "    video_response = youtube.videos().list(\n",
    "        id=','.join(ids_chunk),\n",
    "        part='snippet,statistics'\n",
    "    ).execute()\n",
    "    \n",
    "    for video in video_response['items']:\n",
    "        video_id = video['id']\n",
    "\n",
    "        # Extract data for DataFrame 1\n",
    "        post_id = video_id\n",
    "        post_title = video['snippet']['title']\n",
    "        author = video['snippet']['channelTitle']\n",
    "        date = video['snippet']['publishedAt']\n",
    "        post_content = video['snippet']['description']\n",
    "        comment_number = int(video['statistics'].get('commentCount', '0'))\n",
    "        net_like = int(video['statistics'].get('likeCount', '0')) - int(video['statistics'].get('dislikeCount', '0'))\n",
    "        views = video['statistics']['viewCount']\n",
    "        df1_data.append([post_id, post_title, author, date, post_content, comment_number, net_like, views])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF2 is the comment and specific details of the comments from the videos in DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch comments from videos\n",
    "#Section for df2\n",
    "next_page_token = None\n",
    "while True:\n",
    "    try:\n",
    "        comments_response = youtube.commentThreads().list(\n",
    "            videoId=video_id,\n",
    "            part='id,snippet',\n",
    "            maxResults=50,\n",
    "            textFormat='plainText',\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Extract data for DataFrame 2\n",
    "        for item in comments_response['items']:\n",
    "            unique_id = item['id']\n",
    "            post_id = video_id\n",
    "            author = item['snippet']['topLevelComment']['snippet'].get('authorDisplayName', 'Unknown')\n",
    "            date = item['snippet']['topLevelComment']['snippet'].get('publishedAt', 'Unknown')\n",
    "            comment_content = item['snippet']['topLevelComment']['snippet'].get('textDisplay', '')\n",
    "            reply_id = item['snippet'].get('totalReplyCount', '0')\n",
    "\n",
    "            df2_data.append([unique_id, post_id, author, date, comment_content, reply_id])\n",
    "\n",
    "            # Fetch replies for the current top level comment\n",
    "            if reply_id > 0:\n",
    "                reply_next_page_token = None\n",
    "                while True:\n",
    "                    try:\n",
    "                        reply_response = youtube.comments().list(\n",
    "                            part='id,snippet',\n",
    "                            parentId=unique_id,\n",
    "                            maxResults=10,\n",
    "                            textFormat='plainText',\n",
    "                            pageToken=reply_next_page_token\n",
    "                        ).execute()\n",
    "\n",
    "                        #Extract data for replies\n",
    "                        for reply_item in reply_response['items']:\n",
    "                            reply_unique_id = reply_item['id']\n",
    "                            reply_author = reply_item['snippet'].get('authorDisplay', 'Unknown')\n",
    "                            reply_date = reply_item['snippet'].get('publishedAt', 'Unknown')\n",
    "                            reply_comment_content = reply_item['snippet'].get('textDisplay', '')\n",
    "                            parent_id = unique_id #mapping to the parent comment ID\n",
    "\n",
    "                            df2_data.append([reply_unique_id, post_id, reply_author, reply_date, reply_comment_content,\n",
    "                            0, parent_id])\n",
    "\n",
    "                            reply_next_page_token = reply_response.get('nextPageToken')\n",
    "                            if not reply_next_page_token:\n",
    "                                break\n",
    "                    except HttpError as e:\n",
    "                        print(f\"Skipping replies for comment {unique_id} due to: print {e}\")\n",
    "                        break\n",
    "\n",
    "        # Check if there are more comments to fetch\n",
    "        next_page_token = comments_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"Skipping video {video_id} due to error: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "df1_columns = ['Post_id', 'Post_Title', 'Author', 'Date', 'Post_Content', 'Comment_Number', 'Net_Like', 'Views']\n",
    "df1 = pd.DataFrame(df1_data, columns=df1_columns)\n",
    "\n",
    "df2_columns = ['Unique_id', 'Post_id', 'Author', 'Date', 'Comment_Content', 'Reply_Count', 'Parent_id']\n",
    "df2 = pd.DataFrame(df2_data, columns=df2_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_id</th>\n",
       "      <th>Post_Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post_Content</th>\n",
       "      <th>Comment_Number</th>\n",
       "      <th>Net_Like</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iak-pj6sdFA</td>\n",
       "      <td>IS THIS A REAL ABARTH?! Driving the 500e Elect...</td>\n",
       "      <td>Auto Social UK</td>\n",
       "      <td>2023-07-19T04:45:01Z</td>\n",
       "      <td>Mt expectations were actually not all that hig...</td>\n",
       "      <td>107</td>\n",
       "      <td>428</td>\n",
       "      <td>7314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Ya6yWohTW4</td>\n",
       "      <td>Abarth 500 Electric! - I Might Buy One! Eventu...</td>\n",
       "      <td>Electric Vehicle Man</td>\n",
       "      <td>2023-07-21T15:30:00Z</td>\n",
       "      <td>We test the new (and arguably 1st) electric ho...</td>\n",
       "      <td>203</td>\n",
       "      <td>995</td>\n",
       "      <td>23161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6fDMXjYOsGM</td>\n",
       "      <td>2023 Abarth 500E Turismo First Drive Review: A...</td>\n",
       "      <td>Stef ABtv</td>\n",
       "      <td>2023-07-19T05:30:11Z</td>\n",
       "      <td>Here is the NEW Abarth 500e Turismo Electric F...</td>\n",
       "      <td>136</td>\n",
       "      <td>391</td>\n",
       "      <td>14768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OqQo6VLmnTc</td>\n",
       "      <td>Abarth’s NOISY EV Doesn't Care About Speed!</td>\n",
       "      <td>Fully Charged Show</td>\n",
       "      <td>2023-07-20T14:00:24Z</td>\n",
       "      <td>Jack and Bobby go for a test drive in the firs...</td>\n",
       "      <td>495</td>\n",
       "      <td>5013</td>\n",
       "      <td>144627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigX6_seQr4</td>\n",
       "      <td>New Abarth 500e: Mission Possible. The Mission...</td>\n",
       "      <td>Abarth</td>\n",
       "      <td>2023-06-30T14:13:54Z</td>\n",
       "      <td>It’s no easy feat when you're presented with a...</td>\n",
       "      <td>21</td>\n",
       "      <td>179</td>\n",
       "      <td>565906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Post_id                                         Post_Title  \\\n",
       "0  iak-pj6sdFA  IS THIS A REAL ABARTH?! Driving the 500e Elect...   \n",
       "1  -Ya6yWohTW4  Abarth 500 Electric! - I Might Buy One! Eventu...   \n",
       "2  6fDMXjYOsGM  2023 Abarth 500E Turismo First Drive Review: A...   \n",
       "3  OqQo6VLmnTc        Abarth’s NOISY EV Doesn't Care About Speed!   \n",
       "4  bigX6_seQr4  New Abarth 500e: Mission Possible. The Mission...   \n",
       "\n",
       "                 Author                  Date  \\\n",
       "0        Auto Social UK  2023-07-19T04:45:01Z   \n",
       "1  Electric Vehicle Man  2023-07-21T15:30:00Z   \n",
       "2             Stef ABtv  2023-07-19T05:30:11Z   \n",
       "3    Fully Charged Show  2023-07-20T14:00:24Z   \n",
       "4                Abarth  2023-06-30T14:13:54Z   \n",
       "\n",
       "                                        Post_Content  Comment_Number  \\\n",
       "0  Mt expectations were actually not all that hig...             107   \n",
       "1  We test the new (and arguably 1st) electric ho...             203   \n",
       "2  Here is the NEW Abarth 500e Turismo Electric F...             136   \n",
       "3  Jack and Bobby go for a test drive in the firs...             495   \n",
       "4  It’s no easy feat when you're presented with a...              21   \n",
       "\n",
       "   Net_Like   Views  \n",
       "0       428    7314  \n",
       "1       995   23161  \n",
       "2       391   14768  \n",
       "3      5013  144627  \n",
       "4       179  565906  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_id</th>\n",
       "      <th>Post_id</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment_Content</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9842</th>\n",
       "      <td>UgwqfvUX__-4ZCwegCp4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>tecdessus</td>\n",
       "      <td>2023-07-19T22:59:24Z</td>\n",
       "      <td>An electric bath sounds like a bad idea. Ev's ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>UgypwZid2Eb8wW8oZdZ4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>tecdessus</td>\n",
       "      <td>2023-07-19T23:01:12Z</td>\n",
       "      <td>why are my comment's being deleted ?</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>UgxSxybJ6V1Cdu2QQyx4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>tecdessus</td>\n",
       "      <td>2023-07-19T23:04:17Z</td>\n",
       "      <td>That electric bath should just play Barbie Gir...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>UgzDnIGDPHtMvqeovH54AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>its1me1cal</td>\n",
       "      <td>2023-07-19T23:12:07Z</td>\n",
       "      <td>Sounds like a UFO landing lol</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>UgzTM3QmmmfSmWvCTLZ4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>PoltergeistWorks</td>\n",
       "      <td>2023-07-20T00:27:46Z</td>\n",
       "      <td>More like a slap in the face to ABARTH fans :(...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugxh1xbdgnJjybhTBHp4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>Nomad624</td>\n",
       "      <td>2023-08-08T15:57:07Z</td>\n",
       "      <td>34k for this thing is insane, given that despi...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugz6kUrZ4HcQfUyXXJF4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>Rod Thorpe</td>\n",
       "      <td>2023-08-09T15:33:37Z</td>\n",
       "      <td>£38k!?!? 🤯 Yeah \"electric cars are soooo expen...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgyfaHcnq8D3j-Kl_Ft4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>Mias Greyling</td>\n",
       "      <td>2023-08-12T04:32:24Z</td>\n",
       "      <td>To expensive!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgyQ0dyzYBjdYwZbr1Z4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>Actual Facts</td>\n",
       "      <td>2023-08-13T15:23:11Z</td>\n",
       "      <td>They forgot to put on a boot.</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwSFVXRHkWGpMxzFbt4AaABAg</td>\n",
       "      <td>l-5lVw42VIs</td>\n",
       "      <td>Lotus F</td>\n",
       "      <td>2023-08-14T11:53:51Z</td>\n",
       "      <td>Inspiring the younger generations to inspire t...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9843 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Unique_id      Post_id            Author  \\\n",
       "9842  UgwqfvUX__-4ZCwegCp4AaABAg  l-5lVw42VIs         tecdessus   \n",
       "9841  UgypwZid2Eb8wW8oZdZ4AaABAg  l-5lVw42VIs         tecdessus   \n",
       "9840  UgxSxybJ6V1Cdu2QQyx4AaABAg  l-5lVw42VIs         tecdessus   \n",
       "9839  UgzDnIGDPHtMvqeovH54AaABAg  l-5lVw42VIs        its1me1cal   \n",
       "9838  UgzTM3QmmmfSmWvCTLZ4AaABAg  l-5lVw42VIs  PoltergeistWorks   \n",
       "...                          ...          ...               ...   \n",
       "4     Ugxh1xbdgnJjybhTBHp4AaABAg  l-5lVw42VIs          Nomad624   \n",
       "3     Ugz6kUrZ4HcQfUyXXJF4AaABAg  l-5lVw42VIs        Rod Thorpe   \n",
       "2     UgyfaHcnq8D3j-Kl_Ft4AaABAg  l-5lVw42VIs     Mias Greyling   \n",
       "1     UgyQ0dyzYBjdYwZbr1Z4AaABAg  l-5lVw42VIs      Actual Facts   \n",
       "0     UgwSFVXRHkWGpMxzFbt4AaABAg  l-5lVw42VIs           Lotus F   \n",
       "\n",
       "                      Date                                    Comment_Content  \\\n",
       "9842  2023-07-19T22:59:24Z  An electric bath sounds like a bad idea. Ev's ...   \n",
       "9841  2023-07-19T23:01:12Z               why are my comment's being deleted ?   \n",
       "9840  2023-07-19T23:04:17Z  That electric bath should just play Barbie Gir...   \n",
       "9839  2023-07-19T23:12:07Z                      Sounds like a UFO landing lol   \n",
       "9838  2023-07-20T00:27:46Z  More like a slap in the face to ABARTH fans :(...   \n",
       "...                    ...                                                ...   \n",
       "4     2023-08-08T15:57:07Z  34k for this thing is insane, given that despi...   \n",
       "3     2023-08-09T15:33:37Z  £38k!?!? 🤯 Yeah \"electric cars are soooo expen...   \n",
       "2     2023-08-12T04:32:24Z                                    To expensive!!!   \n",
       "1     2023-08-13T15:23:11Z                      They forgot to put on a boot.   \n",
       "0     2023-08-14T11:53:51Z  Inspiring the younger generations to inspire t...   \n",
       "\n",
       "      Reply_Count Parent_id  \n",
       "9842            0      None  \n",
       "9841            2      None  \n",
       "9840            1      None  \n",
       "9839            0      None  \n",
       "9838            0      None  \n",
       "...           ...       ...  \n",
       "4               0      None  \n",
       "3               0      None  \n",
       "2               0      None  \n",
       "1               0      None  \n",
       "0               0      None  \n",
       "\n",
       "[9843 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(by='Date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining with old and removing duplicates before exporting it to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yt/slyrm7113271w310_rtxsbnw0000gn/T/ipykernel_38571/4248264678.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2_old = pd.read_csv('df2_combined.csv')\n"
     ]
    }
   ],
   "source": [
    "df1_old = pd.read_csv('df1_combined.csv')\n",
    "df2_old = pd.read_csv('df2_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_combined = pd.concat([df1_old, df1], ignore_index=True)\n",
    "df2_combined = pd.concat([df2_old, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157242"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_combined.drop_duplicates(inplace=True)\n",
    "df2_combined.drop_duplicates(subset=['Comment_Content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147397"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df1_combined as CSV\n",
    "df1_combined.to_csv('df1_combined.csv', index=False)\n",
    "\n",
    "# Save df2_combined as CSV\n",
    "df2_combined.to_csv('df2_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f3c74e9254d476e4b254d69434b9f89897df3269b6a5d96ebf52627a70691ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
